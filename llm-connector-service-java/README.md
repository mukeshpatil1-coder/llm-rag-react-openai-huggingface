# ğŸ§  LLM Connector Service (Java + Spring Boot)

This microservice provides a simple REST API to connect with LLMs like OpenAI or Hugging Face. It accepts a prompt and returns the model's response.

---

## ğŸš€ Features

- âœ… REST Endpoint: `/llm/query`
- âœ… Supports OpenAI & Hugging Face Inference APIs
- âœ… API Key-based Authentication
- âœ… Error Handling: timeouts, rate limits, quota errors
- âœ… Built with Java 17 & Spring Boot 3

---

## ğŸ“¦ Prerequisites

- Java 17+
- Maven 3.8+
- Internet access (for calling LLM APIs)
- A valid API key from OpenAI or Hugging Face

---

## ğŸ› ï¸ Build and Run

### 1. Clone the repo

```bash
git clone https://github.com/your-org/llm-connector-service-java.git
cd llm-connector-service-java
```

### 2. Configure your API keys

Edit the `src/main/resources/application.properties` file:

```properties
# === OpenAI ===
openai.api.key=sk-<your-openai-api-key>
openai.model=gpt-3.5-turbo

# === Hugging Face ===
huggingface.api.key=hf_<your-hf-token>
huggingface.model.url=https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium
```

> ğŸ” Use environment variables for production.

### 3. Build the project

```bash
mvn clean install
```

### 4. Run the service

```bash
mvn spring-boot:run
```

The app will start on:  
**http://localhost:8080**

---

## ğŸ§ª Test the API

### â–¶ï¸ POST `/llm/query`

#### Request:

```bash
curl -X POST http://localhost:8080/llm/query \
-H "Content-Type: application/json" \
-d '{"prompt": "Tell me a joke", "provider": "openai"}'
```

```bash
curl -X POST http://localhost:8080/llm/query \
-H "Content-Type: application/json" \
-d '{"prompt": "Tell me a joke", "provider": "huggingface"}'
```

#### Payload Options:

| Field     | Type   | Description                                  |
|-----------|--------|----------------------------------------------|
| `prompt`  | string | The user input prompt                        |
| `provider`| string | `openai` or `huggingface`                    |

---

## âœ… Example Responses

**Hugging Face:**

```json
{
  "response": "Why did the chicken cross the road? To get to the other side!"
}
```

**OpenAI:**

```json
{
  "response": "Sure, here's a joke: ..."
}
```

---

## ğŸ“„ Project Structure

```
llm-connector-service-java/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/java/com/example/llm/
â”‚   â”‚   â”œâ”€â”€ controller/LLMController.java
â”‚   â”‚   â”œâ”€â”€ service/LLMService.java
â”‚   â”‚   â””â”€â”€ dto/PromptRequest.java
â”‚   â””â”€â”€ resources/application.properties
â”œâ”€â”€ pom.xml
â””â”€â”€ README.md
```

---

## âš ï¸ Common Errors

| Error                                | Cause                                  | Fix |
|-------------------------------------|----------------------------------------|-----|
| `429 Too Many Requests`             | Exceeded OpenAI quota                  | Add billing or wait |
| `403 Forbidden (Hugging Face)`      | Invalid or insufficient token          | Use personal access token with "read" |
| `404 Not Found` (Hugging Face)      | Model not public or no API access      | Use a verified model like `DialoGPT-medium` |
| `timeout` or `connection refused`   | Network issue or model sleeping        | Retry or use OpenAI fallback |

---

## ğŸ“˜ References

- [OpenAI API Docs](https://platform.openai.com/docs)
- [Hugging Face Inference API](https://huggingface.co/docs/api-inference/index)
